[project]
name = "ai-assistant"
version = "0.1.0"
description = "Multi-threaded AI assistant with modular perception system"
readme = "README.md"
authors = [
    { name = "enderdincer", email = "ender95dincer@gmail.com" }
]
requires-python = ">=3.11"
dependencies = [
    "opencv-python>=4.9.0",
    "numpy>=1.26.0",
    "pillow>=10.2.0",
]

[project.optional-dependencies]
# Speech-to-Text processor support (using sherpa-onnx for local inference)
stt = [
    "sherpa-onnx>=1.10.0",
    "sounddevice>=0.4.6",
    "soundfile>=0.12.0",
]

# Vision processor support (Qwen3-VL via HuggingFace Transformers)
# Note: Qwen3-VL requires transformers 4.57.0+ (use git install if not yet released)
vision = [
    "torch>=2.0.0",
    "torchvision>=0.15.0",
    "transformers>=4.57.0",
    "accelerate>=0.26.0",
    "qwen-vl-utils>=0.0.8",
]

# Text-to-Speech (TTS) support using Kokoro 82M model
tts = [
    "kokoro-onnx>=1.5.5",
    "onnxruntime>=1.20.0",
    "soundfile>=0.12.0",
    "sounddevice>=0.4.6",
]

# Development tools
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "pytest-cov>=4.1.0",
    "pytest-timeout>=2.2.0",
    "pytest-mock>=3.12.0",
    "mypy>=1.8.0",
    "ruff>=0.2.0",
]

# All optional dependencies
all = [
    "ai-assistant[stt,vision,tts,dev]",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP"]

[tool.mypy]
python_version = "3.11"
strict = true
warn_return_any = true
warn_unused_configs = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "-v --cov=src/ai_assistant --cov-report=term-missing"
